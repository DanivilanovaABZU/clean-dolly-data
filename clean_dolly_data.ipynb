{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"mosaicml/dolly_hhrlhf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly_train = load_dataset(DATASET, split='train')\n",
    "dolly_test = load_dataset(DATASET, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframes\n",
    "dolly_train_df = pd.DataFrame(dolly_train)\n",
    "dolly_test_df = pd.DataFrame(dolly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the prompt template from the prompt column\n",
    "dolly_train_df['prompt'] = dolly_train_df['prompt'].map(lambda x: x.split('\\n\\n### Instruction:\\n')[1].split('\\n\\n### Response:\\n')[0])\n",
    "dolly_test_df['prompt'] = dolly_test_df['prompt'].map(lambda x: x.split('\\n\\n### Instruction:\\n')[1].split('\\n\\n### Response:\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the prompt template has been removed\n",
    "print(dolly_train_df['prompt'][0])\n",
    "print(dolly_test_df['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the trailing new lines\n",
    "dolly_train_df['prompt'] = dolly_train_df['prompt'].map(lambda x: x.strip())\n",
    "dolly_train_df['response'] = dolly_train_df['response'].map(lambda x: x.strip())\n",
    "dolly_test_df['prompt'] = dolly_test_df['prompt'].map(lambda x: x.strip())\n",
    "dolly_test_df['response'] = dolly_test_df['response'].map(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "dolly_train_df = dolly_train_df[~dolly_train_df.duplicated()]\n",
    "dolly_test_df = dolly_test_df[~dolly_test_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some duplicates between the train and test sets\n",
    "dolly_df = pd.concat([dolly_train_df, dolly_test_df])\n",
    "dolly_df[dolly_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decide to remove the duplicates from the train set\n",
    "dolly_train_df = pd.merge(dolly_train_df, dolly_test_df, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are no duplicates\n",
    "dolly_df = pd.concat([dolly_train_df, dolly_test_df])\n",
    "dolly_df[dolly_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty responses\n",
    "dolly_train_df = dolly_train_df[dolly_train_df['response'] != '']\n",
    "dolly_test_df = dolly_test_df[dolly_test_df['response'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking short prompts \n",
    "print(dolly_train_df[dolly_train_df['prompt'].map(lambda x: len(x)) < 3])\n",
    "print()\n",
    "print(dolly_test_df[dolly_test_df['prompt'].map(lambda x: len(x)) < 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing c from the train set\n",
    "dolly_train_df = dolly_train_df[dolly_train_df['prompt'] != 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITY_THRESHOLD = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing high similarity prompts, meaning that the prompt is very similar to the response because it includes the response. You can play with the threshold to see which are the samples that are going to be deleted.\n",
    "dolly_train_df[dolly_train_df.apply(lambda x: similar(x['prompt'], x['response']), axis=1) >= SIMILARITY_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly_test_df[dolly_test_df.apply(lambda x: similar(x['prompt'], x['response']), axis=1) >= SIMILARITY_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove high similarity prompts\n",
    "dolly_train_df = dolly_train_df[dolly_train_df.apply(lambda x: similar(x['prompt'], x['response']), axis=1) < SIMILARITY_THRESHOLD]\n",
    "dolly_test_df = dolly_test_df[dolly_test_df.apply(lambda x: similar(x['prompt'], x['response']), axis=1) < SIMILARITY_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the huggingface dataset from the pandas dataframe\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_ds = Dataset.from_pandas(dolly_train_df).remove_columns(['__index_level_0__'])\n",
    "test_ds = Dataset.from_pandas(dolly_test_df).remove_columns(['__index_level_0__'])\n",
    "\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = train_ds\n",
    "ds['test'] = test_ds\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can upload the dataset to the HuggingFace Hub\n",
    "ds.push_to_hub(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
